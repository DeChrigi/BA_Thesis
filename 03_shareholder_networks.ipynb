{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import relevant libraries for network and data handling / transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import os\n",
    "from networkx import PowerIterationFailedConvergence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read all transformed shareholder files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of dataframes: 61\n"
     ]
    }
   ],
   "source": [
    "# Create list to hold shareholder dataframes\n",
    "shareholder_dfs = []\n",
    "\n",
    "# for each file in directory\n",
    "for filename in os.listdir('./transformed_data/base/shareholders'):\n",
    "    # check if file is a .xlsx file\n",
    "    if filename.endswith('.xlsx'):\n",
    "        # read the file into a dataframe\n",
    "        df = pd.read_excel(f'./transformed_data/base/shareholders/{filename}')\n",
    "        # add the dataframe to the list\n",
    "        shareholder_dfs.append(df)\n",
    "\n",
    "# print number of dataframes, should be equal to number of files -> should be 61\n",
    "print(f\"Number of dataframes: {len(shareholder_dfs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a graph for every year in every file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aalberts\n",
      "ABB\n",
      "Akzo Nobel\n",
      "Alstom SA\n",
      "Areva\n",
      "Asahi\n",
      "AU Optronics\n",
      "BAM\n",
      "Bayern\n",
      "Boliden\n",
      "British Airways\n",
      "Cathay Pacific\n",
      "Chemtura\n",
      "Chimei\n",
      "chiquita\n",
      "Chungwa\n",
      "Commerzbank\n",
      "del monte\n",
      "Dow\n",
      "Elpida\n",
      "ENI\n",
      "EON\n",
      "Exxon Mobil\n",
      "Fuji Electric\n",
      "Fujifilm\n",
      "GDF suez\n",
      "Hannstar Display\n",
      "Henkel\n",
      "hitachi ltd\n",
      "Hitachi Maxell\n",
      "ICI\n",
      "IMI PLC\n",
      "Infineon\n",
      "LG Display\n",
      "Micron\n",
      "Mitsubishi\n",
      "Mueller Industries\n",
      "Nanya Tech\n",
      "NEC\n",
      "Nippon electric glass\n",
      "Panasonic\n",
      "Pilkington\n",
      "procter gamble\n",
      "Qantas\n",
      "rautaruukki\n",
      "Repsol YPF\n",
      "samsung\n",
      "SAS AB\n",
      "Siemens\n",
      "Singapore Airlines\n",
      "SKW Stahl\n",
      "Sony\n",
      "Toshiba\n",
      "Total\n",
      "Unilever NV\n",
      "Unilever PLC\n",
      "Unipetrol\n",
      "United technologies corp\n",
      "Uralita\n",
      "Whirlpool\n",
      "Zeon\n",
      "---Finished---\n"
     ]
    }
   ],
   "source": [
    "for sh_df in shareholder_dfs:\n",
    "    # Get all columns with perc_os in the name\n",
    "    perc_os_columns = sh_df.columns[sh_df.columns.str.contains('perc_os')]\n",
    "    \n",
    "    # Get the name of the company e.g. ABB (Take 0 index because we only have one company per file -> its the same for all rows)\n",
    "    company_name = sh_df[\"company_name\"][0]\n",
    "    \n",
    "    # Print the name of the company to see progress\n",
    "    print(company_name)\n",
    "\n",
    "    # Create a graph for each column with perc_os in the name\n",
    "    for column in perc_os_columns:\n",
    "        G = nx.Graph()\n",
    "\n",
    "        for _, row in sh_df.iterrows():\n",
    "\n",
    "            investor = row[\"investor_name\"] # name of the investor\n",
    "            company = row[\"company_name\"] # redundant, but for clarity\n",
    "            weight = row[column] # percentage ownership\n",
    "\n",
    "            # Check if weight (perc_os) is not null\n",
    "            if not pd.isna(weight):  \n",
    "                G.add_node(company, type=\"Company\") \n",
    "                G.add_node(investor, type=\"Investor\")\n",
    "                G.add_edge(investor, company, weight=weight)\n",
    "        \n",
    "        # Save the graph as a graphml file\n",
    "        nx.write_graphml(G, f\"./transformed_data/shareholder_networks/shareholder_network_{company_name}_{str.replace(column, 'perc_os_', '')}.graphml\", named_key_ids=True, infer_numeric_types=True)\n",
    "\n",
    "print(\"---Finished---\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the herfindal-hirschmann index and the centrality metrics for each file and each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating metrics for Aalberts in 1997\n",
      "Calculating metrics for Aalberts in 1998\n",
      "Calculating metrics for Aalberts in 1999\n",
      "Calculating metrics for Aalberts in 2000\n",
      "Calculating metrics for Aalberts in 2001\n",
      "Calculating metrics for Aalberts in 2002\n",
      "Calculating metrics for Aalberts in 2003\n",
      "Calculating metrics for Aalberts in 2004\n",
      "Calculating metrics for Aalberts in 2005\n",
      "Calculating metrics for Aalberts in 2006\n",
      "Calculating metrics for Aalberts in 2007\n",
      "Calculating metrics for Aalberts in 2008\n",
      "Calculating metrics for Aalberts in 2009\n",
      "Calculating metrics for Aalberts in 2010\n",
      "Calculating metrics for Aalberts in 2011\n",
      "Calculating metrics for ABB in 1997\n",
      "Calculating metrics for ABB in 1998\n",
      "Calculating metrics for ABB in 1999\n",
      "Calculating metrics for ABB in 2000\n",
      "Calculating metrics for ABB in 2001\n",
      "Calculating metrics for ABB in 2002\n",
      "Calculating metrics for ABB in 2003\n",
      "Calculating metrics for ABB in 2004\n",
      "Calculating metrics for ABB in 2005\n",
      "Calculating metrics for ABB in 2006\n",
      "Calculating metrics for ABB in 2007\n",
      "Calculating metrics for ABB in 2008\n",
      "Calculating metrics for ABB in 2009\n",
      "Calculating metrics for ABB in 2010\n",
      "Calculating metrics for ABB in 2011\n",
      "Calculating metrics for Akzo Nobel in 1997\n",
      "Calculating metrics for Akzo Nobel in 1998\n",
      "Calculating metrics for Akzo Nobel in 1999\n",
      "Calculating metrics for Akzo Nobel in 2000\n",
      "Calculating metrics for Akzo Nobel in 2001\n",
      "Calculating metrics for Akzo Nobel in 2002\n",
      "Calculating metrics for Akzo Nobel in 2003\n",
      "Calculating metrics for Akzo Nobel in 2004\n",
      "Calculating metrics for Akzo Nobel in 2005\n",
      "Calculating metrics for Akzo Nobel in 2006\n",
      "Calculating metrics for Akzo Nobel in 2007\n",
      "Calculating metrics for Akzo Nobel in 2008\n",
      "Calculating metrics for Akzo Nobel in 2009\n",
      "Calculating metrics for Akzo Nobel in 2010\n",
      "Calculating metrics for Akzo Nobel in 2011\n",
      "Calculating metrics for Alstom SA in 1997\n",
      "Calculating metrics for Alstom SA in 1998\n",
      "Calculating metrics for Alstom SA in 1999\n",
      "Calculating metrics for Alstom SA in 2000\n",
      "Calculating metrics for Alstom SA in 2001\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 10\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m os\u001b[38;5;241m.\u001b[39mlistdir(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./transformed_data/shareholder_networks/\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m     \u001b[38;5;66;03m# check if file is a .graphml file\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m filename\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.graphml\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m      8\u001b[0m \n\u001b[0;32m      9\u001b[0m         \u001b[38;5;66;03m# read the file into a graph\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m         G \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_graphml\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./transformed_data/shareholder_networks/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mfilename\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m         \u001b[38;5;66;03m# get the company name from the filename\u001b[39;00m\n\u001b[0;32m     13\u001b[0m         company_name \u001b[38;5;241m=\u001b[39m filename\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[1;32m<class 'networkx.utils.decorators.argmap'> compilation 16:7\u001b[0m, in \u001b[0;36margmap_read_graphml_11\u001b[1;34m(path, node_type, edge_key_type, force_multigraph, backend, **backend_kwargs)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mitertools\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mwarnings\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcollections\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m defaultdict\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mcontextlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m contextmanager\n",
      "File \u001b[1;32mc:\\workarea\\BA_Thesis_Git\\BA_Thesis\\.venv\\Lib\\site-packages\\networkx\\utils\\decorators.py:199\u001b[0m, in \u001b[0;36mopen_file.<locals>._open_file.<locals>.<lambda>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m path, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    198\u001b[0m fobj \u001b[38;5;241m=\u001b[39m _dispatch_dict[ext](path, mode\u001b[38;5;241m=\u001b[39mmode)\n\u001b[1;32m--> 199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fobj, \u001b[38;5;28;01mlambda\u001b[39;00m: \u001b[43mfobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclose\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "company_metrics = []\n",
    "\n",
    "# for each graph-file in directory\n",
    "for filename in os.listdir('./transformed_data/shareholder_networks/'):\n",
    "\n",
    "    # check if file is a .graphml file\n",
    "    if filename.endswith('.graphml'):\n",
    "\n",
    "        # read the file into a graph\n",
    "        G = nx.read_graphml(f'./transformed_data/shareholder_networks/{filename}')\n",
    "\n",
    "        # get the company name from the filename\n",
    "        company_name = filename.split('_')[2]\n",
    "\n",
    "        # get the year from the filename\n",
    "        year = filename.split('.')[0][-4:]\n",
    "        \n",
    "        print(f\"Calculating metrics for {company_name} in {year}\")\n",
    "\n",
    "        # get the weights of the edges\n",
    "        weights = [data['weight'] for _, _, data in G.edges(data=True)]\n",
    "\n",
    "        # calculate the herfindahl index and round it to 2 decimal places\n",
    "        herfindahl_index = round(sum([w**2 for w in weights]), 2)\n",
    "\n",
    "        try:\n",
    "            # calculate the centralities for the company node\n",
    "            company_node = [n for n, d in G.nodes(data=True) if d['type'] == 'Company'][0]\n",
    "            degree_centrality = nx.degree_centrality(G)[company_node]\n",
    "            closeness_centrality = nx.closeness_centrality(G)[company_node]\n",
    "            betweenness_centrality = nx.betweenness_centrality(G)[company_node]\n",
    "            try:\n",
    "                # calculate the eigenvector centrality\n",
    "                eigenvector_centrality = nx.eigenvector_centrality(G)[company_node]\n",
    "                katz_centrality = nx.katz_centrality(G)[company_node]\n",
    "            except PowerIterationFailedConvergence:\n",
    "                # if the eigenvector centrality calculation fails, set it to None\n",
    "                eigenvector_centrality = None\n",
    "                katz_centrality = None\n",
    "            pagerank_centrality = nx.pagerank(G)[company_node]\n",
    "        except IndexError:\n",
    "            # if the company node is not found, set the centralities to None\n",
    "            degree_centrality = None\n",
    "            closeness_centrality = None\n",
    "            betweenness_centrality = None\n",
    "            eigenvector_centrality = None\n",
    "            katz_centrality = None\n",
    "            pagerank_centrality = None\n",
    "\n",
    "        \n",
    "        # number of investors\n",
    "        num_investors = len([n for n, d in G.nodes(data=True) if d['type'] == 'Investor'])\n",
    "\n",
    "        # create a dictionary with the metrics\n",
    "        metrics = {\n",
    "            'company_name': company_name,\n",
    "            'year': year,\n",
    "            'num_investors': num_investors,\n",
    "            'herfindahl_index': herfindahl_index,\n",
    "            'degree_centrality': degree_centrality,\n",
    "            'closeness_centrality': closeness_centrality,\n",
    "            'betweenness_centrality': betweenness_centrality,\n",
    "            'eigenvector_centrality': eigenvector_centrality,\n",
    "            'katz_centrality': katz_centrality,\n",
    "            'pagerank_centrality': pagerank_centrality\n",
    "        }\n",
    "\n",
    "        # append the metrics to the list\n",
    "        company_metrics.append(metrics)\n",
    "\n",
    "    \n",
    "# create a dataframe from the list of metrics\n",
    "company_metrics_df = pd.DataFrame(company_metrics)\n",
    "\n",
    "# save the dataframe to a xlsx file\n",
    "company_metrics_df.to_excel('./transformed_data/shareholder_data/company_metrics.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the top 5 investors for each year and each file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List for the top investors\n",
    "top_investors_list = []\n",
    "\n",
    "for sh_df in shareholder_dfs:\n",
    "    # Get all columns with perc_os in the name\n",
    "    perc_os_columns = sh_df.columns[sh_df.columns.str.contains('perc_os')]\n",
    "\n",
    "    # Convert all perc_os columns to numeric\n",
    "    sh_df[perc_os_columns] = sh_df[perc_os_columns].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "    # Get the name of the company e.g. ABB (Take 0 index because we only have one company per file -> its the same for all rows)\n",
    "    company_name = sh_df[\"company_name\"][0]\n",
    "\n",
    "    for column in perc_os_columns:\n",
    "        year = column[-4:]\n",
    "\n",
    "        # Get top 5 investors for the column\n",
    "        top5 = sh_df.nlargest(5, column)[[\"investor_name\", column]].reset_index(drop=True)\n",
    "\n",
    "        for rank in range(5):\n",
    "            try:\n",
    "                investor = top5.loc[rank, \"investor_name\"]\n",
    "                perc = top5.loc[rank, column]\n",
    "\n",
    "                if pd.isna(perc):\n",
    "                    continue  # If no value is available, skip this investor\n",
    "\n",
    "                # Result dictionary\n",
    "                result = {\n",
    "                    \"company_name\": company_name,\n",
    "                    \"year\": int(year),\n",
    "                    \"rank\": rank + 1,\n",
    "                    \"investor_name\": investor,\n",
    "                    \"perc_os\": perc\n",
    "                }\n",
    "\n",
    "                # Append to the list\n",
    "                top_investors_list.append(result)\n",
    "\n",
    "            except IndexError:\n",
    "                # less than 5 investors\n",
    "                continue\n",
    "\n",
    "# Transform the list into a DataFrame\n",
    "top_investors_df = pd.DataFrame(top_investors_list)\n",
    "\n",
    "# Sort the DataFrame by company_name, year, and rank\n",
    "top_investors_df = top_investors_df.sort_values(by=[\"company_name\", \"year\", \"rank\"])\n",
    "\n",
    "top_investors_df.to_excel(\"transformed_data/shareholder_data/top_investors.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
